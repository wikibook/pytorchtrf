{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c3e6c-e7fd-46b6-ae43-d384bf83d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "print(transformed_image.shape)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(degrees=30, expand=False, center=None),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041099fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=(512, 512)),\n",
    "        transforms.Pad(padding=50, fill=(127, 127, 255), padding_mode=\"constant\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512))\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a821d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomAffine(\n",
    "            degrees=15, translate=(0.2, 0.2),\n",
    "            scale=(0.8, 1.2), shear=15\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ece4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3, contrast=0.3,\n",
    "            saturation=0.3, hue=0.3\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        transforms.ToPILImage()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_ # Deprecated 오류 방지\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "class IaaTransforms:\n",
    "    def __init__(self):\n",
    "        self.seq = iaa.Sequential([\n",
    "            iaa.SaltAndPepper(p=(0.03, 0.07)),\n",
    "            iaa.Rain(speed=(0.3, 0.7))\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, images): \n",
    "        images = np.array(images)\n",
    "        print(images.shape, images.dtype)\n",
    "        augmented = self.seq.augment_image(images)\n",
    "        return Image.fromarray(augmented)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    IaaTransforms()\n",
    "])\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1.0, value=0),\n",
    "    transforms.RandomErasing(p=1.0, value='random'),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a62eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class Mixup:\n",
    "    def __init__(self, target, scale, alpha=0.5, beta=0.5):\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        target = self.target.resize(self.scale)\n",
    "        target = np.array(target)\n",
    "        mix_image = image * self.alpha + target * self.beta\n",
    "        return Image.fromarray(mix_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512)),\n",
    "        Mixup(\n",
    "            target=Image.open(\"../datasets/images/dog.jpg\"),\n",
    "            scale=(512, 512),\n",
    "            alpha=0.5,\n",
    "            beta=0.5\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "plt.imshow(transformed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
