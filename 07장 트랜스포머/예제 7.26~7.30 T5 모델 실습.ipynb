{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76f6d-3094-4ca7-bc0b-e9254b4ea8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
    "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
    "df[\"text\"] = \"summarize: \" + df[\"text\"]\n",
    "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")\n",
    "\n",
    "print(f\"Source News : {train.text.iloc[0][:200]}\")\n",
    "print(f\"Summarization : {train.prediction.iloc[0][:50]}\")\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f83bba-91e9-4dc6-bc96-d4764f8ec065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    source = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    target = tokenizer(\n",
    "        text=data.prediction.tolist(),\n",
    "        padding=\"max_length\", \n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    source_ids = source[\"input_ids\"].squeeze().to(device)\n",
    "    source_mask = source[\"attention_mask\"].squeeze().to(device)\n",
    "    target_ids = target[\"input_ids\"].squeeze().to(device)\n",
    "    target_mask = target[\"attention_mask\"].squeeze().to(device)\n",
    "    return TensorDataset(source_ids, source_mask, target_ids, target_mask)\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-small\"\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(next(iter(train_dataloader)))\n",
    "print(tokenizer.convert_ids_to_tokens(21603))\n",
    "print(tokenizer.convert_ids_to_tokens(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c2969-7300-4306-aef1-6091328e2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-small\",\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81b0e5-327c-4604-bb8b-fff9786c5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "        decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "        labels = target_ids[:, 1:].clone().detach()\n",
    "        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "            decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "            labels = target_ids[:, 1:].clone().detach()\n",
    "            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=source_ids,\n",
    "                attention_mask=source_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss\n",
    "\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/T5ForConditionalGeneration.pt\")\n",
    "        print(\"Saved the model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422e000-d322-4152-a47a-037c35008eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for source_ids, source_mask, target_ids, target_mask in test_dataloader:\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            max_length=128,\n",
    "            num_beams=3,\n",
    "            repetition_penalty=2.5,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "        for generated, target in zip(generated_ids, target_ids):\n",
    "            pred = tokenizer.decode(\n",
    "                generated, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            actual = tokenizer.decode(\n",
    "                target, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            print(\"Generated Headline Text:\", pred) \n",
    "            print(\"Actual Headline Text   :\", actual) \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
